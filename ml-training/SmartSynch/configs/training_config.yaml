# Model Configuration
model:
  name: "all-MiniLM-L6-v2"
  num_epochs: 50
  batch_size: 16
  learning_rate: 0.0001
  dropout_rate: 0.3
  early_stopping_patience: 7
  validation_split: 0.2
  num_classes: 5  # For Development, Design, Research, Meeting, Planning
  embedding_dim: 384  # MiniLM-L6-v2 output dimension
  model_dir: "models/fine_tuned"
  attention_heads: 4  # New parameter for attention mechanism

# Training Parameters
training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 100
  patience: 5  # Early stopping patience
  validation_split: 0.2

# Logging and Checkpoints
logging:
  log_interval: 10  # Log every N batches
  save_best_only: true
  metrics:
    - accuracy
    - precision
    - recall
    - f1

# Early Stopping
early_stopping:
  monitor: "val_loss"
  min_delta: 0.001
  patience: 5
  mode: "min"

# Model Saving
saving:
  base_dir: "models/fine_tuned"
  save_format: "model.pt"
  save_metadata: true

